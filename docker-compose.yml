version: "3.9"

services:
  kafka:
    image: bitnami/kafka:3.6
    container_name: kafka
    ports:
      - "19092:19092"
    environment:
      - KAFKA_ENABLE_KRAFT=yes
      - KAFKA_CFG_PROCESS_ROLES=broker,controller
      - KAFKA_CFG_LISTENERS=INTERNAL://:9092,CONTROLLER://:9093,EXTERNAL://:19092
      - KAFKA_CFG_ADVERTISED_LISTENERS=INTERNAL://kafka:9092,EXTERNAL://localhost:19092
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=INTERNAL:PLAINTEXT,CONTROLLER:PLAINTEXT,EXTERNAL:PLAINTEXT
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_CFG_NODE_ID=1
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=1@kafka:9093
      - KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=true
      - KAFKA_CFG_OFFSETS_TOPIC_REPLICATION_FACTOR=1
      - KAFKA_CFG_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=1
      - KAFKA_CFG_TRANSACTION_STATE_LOG_MIN_ISR=1
      - KAFKA_HEAP_OPTS=-Xmx512m -Xms512m
    healthcheck:
      test: ["CMD", "bash", "-lc", "kafka-topics.sh --bootstrap-server localhost:9092 --list | cat"]
      interval: 10s
      timeout: 5s
      retries: 12

  

  postgres:
    image: postgres:15
    container_name: postgres
    environment:
      - POSTGRES_USER=${POSTGRES_USER:-postgres}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-postgres}
      - POSTGRES_DB=${POSTGRES_DB:-postgres}
    ports:
      - "5432:5432"
    volumes:
      - pgdata:/var/lib/postgresql/data

  spark-master:
    image: bitnami/spark:3.5
    container_name: spark-master
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_HOST=spark-master
      - SPARK_DRIVER_MEMORY=1g
      - SPARK_WORKER_MEMORY=1g
    ports:
      - "7077:7077"
      - "8080:8080"
    volumes:
      - ./src:/opt/app/src
      - ./data:/opt/app/data
    depends_on:
      - kafka
      - postgres

  spark-worker:
    image: bitnami/spark:3.5
    container_name: spark-worker
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=2g
    depends_on:
      - spark-master
    volumes:
      - ./data:/opt/app/data

  airflow-webserver:
    image: apache/airflow:2.9.1-python3.11
    container_name: airflow-webserver
    ports:
      - "8088:8080"
    environment:
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__WEBSERVER__EXPOSE_CONFIG=True
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://${POSTGRES_USER:-postgres}:${POSTGRES_PASSWORD:-postgres}@postgres/${POSTGRES_DB:-postgres}
      - _PIP_ADDITIONAL_REQUIREMENTS=apache-airflow-providers-apache-spark apache-airflow-providers-postgres soda-core-postgres
    volumes:
      - ./dags:/opt/airflow/dags
      - ./docker/airflow/requirements.txt:/requirements.txt
      - ./soda:/opt/airflow/soda
      - ./data:/opt/app/data
    command: webserver
    depends_on:
      - postgres

  airflow-scheduler:
    image: apache/airflow:2.9.1-python3.11
    container_name: airflow-scheduler
    environment:
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://${POSTGRES_USER:-postgres}:${POSTGRES_PASSWORD:-postgres}@postgres/${POSTGRES_DB:-postgres}
      - _PIP_ADDITIONAL_REQUIREMENTS=apache-airflow-providers-apache-spark apache-airflow-providers-postgres soda-core-postgres
    volumes:
      - ./dags:/opt/airflow/dags
      - ./soda:/opt/airflow/soda
      - ./data:/opt/app/data
    command: scheduler
    depends_on:
      - airflow-webserver

  producer:
    image: python:3.11-slim
    container_name: producer
    profiles: ["dev"]
    environment:
      - KAFKA_BOOTSTRAP=kafka:9092
      - GBFS_STATUS_URL=${GBFS_STATUS_URL:-https://gbfs.citibikenyc.com/gbfs/en/station_status.json}
      - PRODUCER_POLL_SECS=${PRODUCER_POLL_SECS:-30}
      - KAFKA_TOPIC=${KAFKA_TOPIC:-gbfs.station_status.json}
    volumes:
      - ./src:/opt/app/src
    depends_on:
      - kafka
    command: bash -lc "pip install --no-cache-dir kafka-python requests tenacity && python /opt/app/src/ingestion/producer.py"

volumes:
  pgdata:


